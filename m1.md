# Definitions and (some) fundamental notions

## (1) What is denoted by Deduction, Abduction, and Induction?  
- Deduction:starts with general axioms and derives specific theorems from there
- Abduction: starts from a special example and attempts to derive facts
- Induction:starts with data and derives general rules
  
## (2) What is special to induction, how to proceed?  
- Induction ‚Äústarts with data to derive general rules (models)‚Äù and relies on limited samples plus prior assumptions (inductive bias), with its generalization verified on new data.
  
## (3) From the point of view of verification, what can be expected from induction?  
- Induction cannot prove a theory absolutely; it only supports or falsifies a theory through data. The expectation is that the model will predict new data accurately and generalize well.
  
## (4) What is the meaning of ‚ÄúInductive Learning Hypothesis‚Äù and ‚ÄúLearning Bias‚Äù?  
- Inductive Learning Hypothesis: The assumption that a ‚Äúfinite training set‚Äù represents the overall problem, allowing the learning of a model that generalizes to unseen data.
- Learning Bias: The prior knowledge or assumptions that constrain the search space during learning and determine the model‚Äôs applicability.
  
## (5) Which fundamental equivalence is valid between deduction and induction?  
*(The answer needs knowledge of the definition of inductive bias).*  
-When prior assumptions (inductive bias) are incorporated, inductive learning can be regarded as an ‚Äúequivalent deductive system.‚Äù 

## (6) What is supervised learning? (Or unsupervised? Or lazy?)  
- Supervised Learning: Learning the mapping between inputs and outputs using labeled data;
- Unsupervised Learning: Discovering underlying structures from unlabeled data;
- Lazy Learning: Not building a model in advance but using training data directly at prediction time (e.g., K-Nearest Neighbors). 

## (7) What is the goal?  
- The goal is to learn a model that can accurately predict new data, thereby achieving good generalization. 

## (8) How do probabilistic and deterministic approaches differ in this?  
- Probabilistic methods: Describe uncertainty using probability distributions and provide confidence measures with predictions;
-Deterministic methods: Provide fixed outputs without explicitly representing uncertainty. 

## (9) How do model selection and parameter optimization differ? Give an example.  
- Model selection: Deciding which model to use (for example, choosing between a linear, polynomial, or other nonlinear model);
- Parameter optimization: Tuning the parameters within the chosen model to minimize error (e.g., using least squares to determine polynomial coefficients).
- For instance, in polynomial curve fitting, one first selects the degree of the polynomial (model selection) and then computes the coefficients using the least squares method (parameter optimization). 

---

# Basics of Supervised Learning: Regression  

## (1) Sketch the basic example from the lecture for supervised learning! *(Draw)*  
## (2) Which concrete data model is used? *(Write down)*  
- $$y(x, w) = w_0 + w_1 \cdot x + w_2 \cdot x^2 + \dots + w_{m-1} \cdot x^{(m-1)}$$

## (3) How is learning organized here?  
- Learning is organized into two main parts:
-Model selection ‚Äì choosing the form and complexity of the model (e.g. selecting the degree of the polynomial);
- Parameter optimization ‚Äì learning the model parameters by minimizing the error function (the empirical error).
The lecture highlights the distinction between ‚Äúcreate model‚Äù and ‚Äúlearn parameters.‚Äù

## (4) Write down the error function!  
- $$E(w) = \frac{1}{2} \sum_{n=1}^{N} \left[ y(x_n, w) - t_n \right]^2$$where N is the number of data points and t‚Çô the target value.

## (5) What is model selection in the example?  
- Model selection refers to choosing the model‚Äôs ‚Äúform‚Äù and ‚Äúcomplexity‚Äù based on the data.In this example, it means selecting a polynomial model and its degree, which determines the number of parameters and the model‚Äôs capacity.

## (6) What is regularization and why is it needed? *(General question, requires general answer!)*  
- Regularization is a technique to prevent overfitting by adding a penalty term to the error function to restrict the size of the model parameters, thereby controlling model complexity.Its purpose is to avoid the model from ‚Äúmemorizing‚Äù the noise in the training data and to improve generalization to new data.

## (7) How is regularization done in the example? *(Concrete question, requires concrete formula)*  
- In the example, regularization is performed by adding a penalty term to the sum-of-squares error function, resulting in the regularized error function: $$E_{\text{reg}}(w) = E(w) + \frac{\lambda}{2} \cdot \|w\|^2$$ where Œª is the regularization parameter controlling the strength of the penalty.

## (8) Sketch the typical graph that indicates overfitting! *(BTW: What is overfitting?)*  

---

# Basics of Supervised Learning: Probabilistic Approach  

## (1) Write down the stochastic data model. Which distribution do we use for the noise?  
- The stochastic data model is $$t = y(x,w) + N(0,\beta^{-1})$$ where the noise is modeled as a Gaussian (normal) distribution, i.e., $\nu \sim \mathcal{N}(0, \beta^{-1})$.   

## (2) Sketch (i.e., draw!) the picture for the example from the lecture. Where to draw the noise?  
## (3) How to arrive at the likelihood for one point from the stochastic data model? How at the data likelihood?  
-For a single data point, from $$t = y(x,w) + N(0,\beta^{-1})$$we have $$p\left(t\mid x,w,\beta\right)=N\left(t\mid y\left(x,w\right),\beta^{-1}\right).$$Assuming that the data points are independent, the likelihood for the whole dataset is $$L(w) = P(T \mid X, w, \beta)
= \prod_{n=1}^{N} \mathcal{N}\bigl(t_n \mid y(x_n, w), \beta^{-1}\bigr) $$

## (4) Which fundamental assumption underlies the formulation of the data likelihood in this form?  
- The fundamental assumption is that the data points are independent and identically distributed (i.i.d.) and that the noise is Gaussian.

## (5) How to find the parameters from this approach? *(Write down the essential steps of the derivation of the best parameters)*  
- Write down the likelihood for the entire dataset: $$L(w) = \prod_{n=1}^{N} \mathcal{N}\bigl(t_n \mid y(x_n, w), \beta^{-1}\bigr)$$
- Take the logarithm to obtain the log-likelihood:$$ log L(w) = \sum_{n=1}^{N} log\mathcal{N}\bigl(t_n \mid y(x_n, w), \beta^{-1}\bigr)$$
- Simplify the log-likelihood using the properties of the Gaussian distribution, which leads to an expression proportional to the sum-of-squares error (plus constant terms).
- Optimize by setting the derivative with respect to ùë§ to zero, thereby obtaining the maximum likelihood estimator $w_{ML}$.

## (6) How to generalize from the maximum likelihood?  
-Generalization is achieved by using the predictive distribution. With the obtained maximum likelihood parameters $w_{ML}$ and $\beta_{ML}$, the predictive distribution for a new input ùë• is $$p\left(t\mid x,w_{ML},\beta_{ML}\right)=N\left(t\mid y\left(x,w_{ML}\right),\beta_{ML}^{-1}\right),$$ which provides both the prediction and its uncertainty.

## (7) What is the relation to the deterministic approach (with the same model)?  
- Under the Gaussian noise assumption, the maximum likelihood approach is equivalent to the deterministic approach that minimizes the sum-of-squares error; both lead to the same optimal parameters and predictions.

## (8) Write down the Bayes formula and name the terms.  
- Bayes' formula is $$P(w \mid D) = \frac{P(D \mid w)\,P(w)}{P(D)}$$
where:<br>
$P(w)$ is the prior,<br>
$P(D \mid w)$ is the likelihood,<br>
$P(D)$ is the evidence (or marginal likelihood),<br>
$P(w \mid D)$ is the posterior.

## (9) Interpret the terms, what do they express?  
- Prior $P(w)$: Represents our initial belief or uncertainty about the parameters before observing any data.<br>
- Likelihood $P(D \mid w)$: Expresses the probability of observing the data ùê∑ given the parameters ùë§.<br>
- Evidence $P(D)$: Acts as a normalization constant ensuring the posterior is a proper probability distribution.<br>
- Posterior $P(w \mid D)$: Represents our updated belief about the parameters after observing the data.

## (10) How to get the MAP parameters?  
- The MAP parameters are obtained by maximizing the posterior probability: $w_{MAP} = \arg\max_{w} P(w \mid D)$<br>In practice, this is equivalent to minimizing the negative log-posterior, which typically leads to a regularized error function.

## (11) In which sense is this equivalent to the deterministic approach? 
- The MAP estimation, when using a Gaussian prior, is equivalent to solving a regularized least-squares problem. In other words, maximizing the posterior (or minimizing the negative log-posterior) yields the same solution as the deterministic approach with regularization, thus preventing overfitting.



## (12) What is expressed by the predictive distribution and how to generalize with it?  
-The predictive distribution expresses the probability of a new output ùë° given a new input ùë• and the training data (ùëã,ùëá).<br>
In the Bayesian framework, it is obtained by integrating over the uncertainty in the parameters:$$p(t \mid x, X, T) = \int p(t \mid x, w) p(w \mid D) \, dw $$<br>
This provides not only the predicted value (mean) but also quantifies the uncertainty (variance) in the prediction.

## (13) Sketch the procedure for incremental Bayesian learning! *(General question, general answer required).*  

---